# Spark-Streaming-using-Kafka
This Project is done using Spark Core,SparkSQL,Spark Streaming,Scala and functional programming.
We get the information of STM every day and need to run an ETL pipeline to enrich data for reporting
and analysis purpose in real-time.Data is split in two
1. A set of tables that build dimension (batch style)
2. Stop times that needed to be enriched for analysis and reporting (streaming)
